{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5581b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaAllTopicsConsumer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read from all topics using regex pattern\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribePattern\", \".*\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "# Decode bytes to strings\n",
    "parsed_df = df.selectExpr(\"topic\", \"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "# Show the stream in the console\n",
    "query = parsed_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
